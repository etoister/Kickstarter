{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os, json\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func that reads the ''category'' column (from JSON format)\n",
    "def CustomParser1(df):\n",
    "    j1 = json.loads(df)\n",
    "    return j1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part loads as many files as instructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files (n):\n",
    "    df=pd.DataFrame()\n",
    "    read_df=pd.DataFrame()\n",
    "    a=[\"%03d\" % x for x in range(n)]\n",
    "    for filenum in a:\n",
    "        filename='Data/Kickstarter'+filenum+'.csv'\n",
    "        read_df=pd.read_csv(filename,converters={'category':CustomParser1},header=0)\n",
    "        df=pd.concat([df,read_df],ignore_index=True)\n",
    "        \n",
    "    df.info()\n",
    "    return df\n",
    "Filesnum=input('How many file should I load? 1..54  ')\n",
    "df=load_files (int(Filesnum))\n",
    "df.to_csv('data/jointfile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('Data/Kickstarter.csv',converters={'category':CustomParser1},header=0)\n",
    "#make differnt columns out of ''category'' format\n",
    "df[sorted(df['category'][0].keys(),reverse=False)] = df['category'].apply(pd.Series) \n",
    "df1=df[['category','color','parent_id','urls','id','name','position']]\n",
    "df['category.parent_id']=df1['position']\n",
    "df['category.id']=df1['color']\n",
    "df['category.position']=df1['parent_id']\n",
    "df['category.name']=df1['id']\n",
    "df['category.slug']=df1['name']\n",
    "#split ''slug'' and leaves just the main category name\n",
    "df['category.slug']=df['category.slug'].apply(lambda x: x.split('/'))\n",
    "df['category.slug']=df['category.slug'].apply(lambda x: x.pop(0))\n",
    "df[['category','category.parent_id','category.id','category.name','category.position','category.slug']][:1]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func that reads the ''creator'' column (from JSON format).\n",
    "#some of the cells cause problems \n",
    "    #for exemple- the cell JSON format include double apostrophes in nicknames like \"Elad \"Superman\" Toister\" confused it.\n",
    "\n",
    "def CustomParser2(df2):\n",
    "    try:\n",
    "        j2 = json.loads(df2)\n",
    "        return j2\n",
    "    except: #the func pass all the errored rows and return 0 to the \"creator\" columnn. \n",
    "        return 0\n",
    "    pass\n",
    "            \n",
    "df2=pd.read_csv('data/jointfile.csv',converters={'creator':CustomParser2},header=0)\n",
    "#count and collect all the droped rows- so we can know the \"cost\" of te dropping (and maybe i will succed to solve it in the future)\n",
    "droped=df2.loc[df2['creator']==0,['creator']]\n",
    "df2=df2.loc[df2['creator']!=0]\n",
    "drop_list=list(droped.index)\n",
    "#df['creator'].iloc[drop_list]=df['creator'].iloc[drop_list].apply(lambda x: x.replace(' ',',')) is a start of a solution\n",
    "df=df.drop(index=drop_list)\n",
    "print('droped rows:',len(drop_list),drop_list)\n",
    "print (len(df))\n",
    "print (len(df2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 func that make diffent columns out of \"creator\" column (the auto func i used before don't works here. i did it manually)\n",
    "df2['creator_name']=df2['creator'].apply(lambda x: x['name'])\n",
    "df2['creator_id']=df2['creator'].apply(lambda x: x['id'])\n",
    "#\"inject\" it back to the original df\n",
    "df['creator_name']=df2['creator_name']\n",
    "df['creator_id']=df2['creator_id']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning func\n",
    "def clean(df):\n",
    "    data = df.copy()\n",
    "    #this is important beacuse this is the part we dicided  which columns entered the data set.\n",
    "    #the main structure is like in the exemple but i manipulate and add some additional columns i think we need to include(*marked) . \n",
    "    selected_cols = ['creator_name', #*\n",
    "                     'creator_id', #*\n",
    "                     'backers_count',\n",
    "                     'blurb',\n",
    "                     'is_starred', #*\n",
    "                     'category.id', #*\n",
    "                     'category.name',\n",
    "                     'category.parent_id',\n",
    "                     'category.slug',\n",
    "                     'country',\n",
    "                     'created_at',\n",
    "                     'currency',  \n",
    "                     'deadline',\n",
    "                     'goal',\n",
    "                     'launched_at',\n",
    "                     'spotlight',\n",
    "                     'staff_pick',\n",
    "                     'state',\n",
    "                     'usd_pledged',\n",
    "                     'usd_type']\n",
    "    data = data[selected_cols]\n",
    "    data['is_starred']=data['is_starred'].replace({1: True , None: False})\n",
    "    data = data.dropna()\n",
    "    successful = data['state'] == \"successful\"\n",
    "    failed = data['state'] == \"failed\"\n",
    "    cancelled = data['state'] == \"cancelled\"\n",
    "    suspended = data['state'] == \"suspended\"\n",
    "    data = data.loc[failed | successful | cancelled | suspended]\n",
    "    num_cols = ['usd_pledged',\n",
    "                'deadline',\n",
    "                'created_at',\n",
    "                'launched_at']\n",
    "    data[num_cols] = data[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    data['created_at'] = pd.to_datetime(data['created_at'],unit='s')\n",
    "    data['launched_at'] = pd.to_datetime(data['launched_at'],unit='s')\n",
    "    data['deadline'] = pd.to_datetime(data['deadline'],unit='s')\n",
    "    return data\n",
    "\n",
    "data = clean(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def engineer_features(data):\n",
    "    #make state 1 or 0\n",
    "    data['state'].replace('suspended','failed',inplace=True)   \n",
    "    data['state_num'] = data['state'].apply(lambda x: 1 if x=='successful' else 0)\n",
    "    #time to reletive time\n",
    "    data['launched_at_hr'] = data['launched_at'].apply(lambda x: x.hour) + 1\n",
    "    data['launched_at_day_in_week'] = data['launched_at'].apply(lambda x: x.dayofweek + 1)\n",
    "    data['launched_at_day_in_month'] = data['launched_at'].apply(lambda x: x.day ) #Elad's comment\n",
    "    data['launched_at_mo'] = data['launched_at'].apply(lambda x: x.month)\n",
    "    data['launched_at_yr'] = data['launched_at'].apply(lambda x: x.year)\n",
    "    data['deadline_hr'] = data['deadline'].apply(lambda x: x.hour) + 1\n",
    "    data['deadline_day_in_week'] = data['deadline'].apply(lambda x: x.dayofweek + 1) \n",
    "    data['deadline_day_in_month'] = data['deadline'].apply(lambda x: x.day ) #Elad's comment\n",
    "    data['deadline_mo'] = data['deadline'].apply(lambda x: x.month)\n",
    "    data['deadline_yr'] = data['deadline'].apply(lambda x: x.year)\n",
    "    data['created_at_hr'] = data['created_at'].apply(lambda x: x.hour) + 1\n",
    "    data['created_at_day_in_week'] = data['created_at'].apply(lambda x: x.dayofweek + 1) \n",
    "    data['created_at_day_in_month'] = data['created_at'].apply(lambda x: x.day )  #Elad's comment\n",
    "    data['created_at_mo'] = data['created_at'].apply(lambda x: x.month)\n",
    "    data['created_at_yr'] = data['created_at'].apply(lambda x: x.year)\n",
    "    data['count'] = 1\n",
    "    data['success'] = (data['state'] == 'successful')\n",
    "    data['launched-created'] = (data.launched_at - data.created_at).dt.components.days\n",
    "    data['deadline-launched'] = (data.deadline - data.launched_at).dt.components.days\n",
    "    data=data.drop(['launched_at','created_at','deadline'],axis=1) #drop original time col\n",
    "    data['pledge_perc']=data['usd_pledged']/data['goal']*100\n",
    "    return data\n",
    "data = engineer_features(data)\n",
    "data.info()\n",
    "data.to_csv('Data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import set\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "set(font_scale=2)\n",
    "b=sns.countplot(x='category.slug', hue='success',data=data)\n",
    "#b.axes.set_title(\"Title\",fontsize=30)\n",
    "b.set_xlabel(\"Categories\",fontsize=18)\n",
    "b.set_ylabel(\"Count\",fontsize=18)\n",
    "b.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP=np.clip(data['pledge_perc'], 0, 300)\n",
    "fig=PP.hist(bins = 200, figsize = (20,15),color='gold')\n",
    "fig.set_xlabel(\"% of Capital raised from initial goal\",fontsize=18,color='b')\n",
    "fig.set_ylabel(\"Count\",fontsize=18,color='b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.corr()\n",
    "corr_matrix[\"success\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix[(corr_matrix<1) & ((corr_matrix >= 0.2) | (corr_matrix <= -0.2)) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x='category.slug', y='usd_pledged', data=data, alpha=0.5, color='r')\n",
    "plt.ylabel(\"USD Pledged\",fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
