{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os, json\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func that reads the ''category'' column (from JSON format)\n",
    "def CustomParser1(df):\n",
    "    j1 = json.loads(df)\n",
    "    return j1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part loads as many files as instructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many file should I load? 1..54  3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11442 entries, 0 to 3811\n",
      "Data columns (total 37 columns):\n",
      "backers_count               11442 non-null int64\n",
      "blurb                       11442 non-null object\n",
      "category                    11442 non-null object\n",
      "converted_pledged_amount    11442 non-null int64\n",
      "country                     11442 non-null object\n",
      "created_at                  11442 non-null int64\n",
      "creator                     11442 non-null object\n",
      "currency                    11442 non-null object\n",
      "currency_symbol             11442 non-null object\n",
      "currency_trailing_code      11442 non-null bool\n",
      "current_currency            11442 non-null object\n",
      "deadline                    11442 non-null int64\n",
      "disable_communication       11442 non-null bool\n",
      "friends                     4 non-null object\n",
      "fx_rate                     11442 non-null float64\n",
      "goal                        11442 non-null float64\n",
      "id                          11442 non-null int64\n",
      "is_backing                  4 non-null object\n",
      "is_starrable                11442 non-null bool\n",
      "is_starred                  4 non-null object\n",
      "launched_at                 11442 non-null int64\n",
      "location                    11347 non-null object\n",
      "name                        11442 non-null object\n",
      "permissions                 4 non-null object\n",
      "photo                       11442 non-null object\n",
      "pledged                     11442 non-null float64\n",
      "profile                     11442 non-null object\n",
      "slug                        11442 non-null object\n",
      "source_url                  11442 non-null object\n",
      "spotlight                   11442 non-null bool\n",
      "staff_pick                  11442 non-null bool\n",
      "state                       11442 non-null object\n",
      "state_changed_at            11442 non-null int64\n",
      "static_usd_rate             11442 non-null float64\n",
      "urls                        11442 non-null object\n",
      "usd_pledged                 11442 non-null float64\n",
      "usd_type                    11283 non-null object\n",
      "dtypes: bool(5), float64(5), int64(7), object(20)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "def load_files (n):\n",
    "    df=pd.DataFrame()\n",
    "    read_df=pd.DataFrame()\n",
    "    a=[\"%03d\" % x for x in range(n)]\n",
    "    for filenum in a:\n",
    "        filename='Data/Kickstarter'+filenum+'.csv'\n",
    "        read_df=pd.read_csv(filename,converters={'category':CustomParser1},header=0)\n",
    "        df=pd.concat([df,read_df])\n",
    "    df.info()\n",
    "    return df\n",
    "Filesnum=input('How many file should I load? 1..54  ')\n",
    "df=load_files (int(Filesnum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df=pd.read_csv('Data/Kickstarter.csv',converters={'category':CustomParser1},header=0)\n",
    "#make differnt columns out of ''category'' format\n",
    "df[sorted(df['category'][0].keys(),reverse=False)] = df['category'].apply(pd.Series) \n",
    "df1=df[['category','color','parent_id','urls','id','name','position']]\n",
    "df['category.parent_id']=df1['position']\n",
    "df['category.id']=df1['color']\n",
    "df['category.position']=df1['parent_id']\n",
    "df['category.name']=df1['id']\n",
    "df['category.slug']=df1['name']\n",
    "#split ''slug'' and leaves just the main category name\n",
    "df['category.slug']=df['category.slug'].apply(lambda x: x.split('/'))\n",
    "df['category.slug']=df['category.slug'].apply(lambda x: x.pop(0))\n",
    "df[['category','category.parent_id','category.id','category.name','category.position','category.slug']][:1]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-63cf18e64d6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdrop_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdroped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#df['creator'].iloc[drop_list]=df['creator'].iloc[drop_list].apply(lambda x: x.replace(' ',',')) is a start of a solution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'droped rows:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdrop_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3-1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3692\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3693\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3694\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3696\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3-1\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3106\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3108\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3-1\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3158\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{} not found in axis'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3160\u001b[0m             \u001b[0mslicer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[] not found in axis'"
     ]
    }
   ],
   "source": [
    "# func that reads the ''creator'' column (from JSON format).\n",
    "#some of the cells cause problems \n",
    "    #for exemple- the cell JSON format include double apostrophes in nicknames like \"Elad \"Superman\" Toister\" confused it.\n",
    "\n",
    "def CustomParser2(df2):\n",
    "    try:\n",
    "        j2 = json.loads(df2)\n",
    "        return j2\n",
    "    except: #the func pass all the errored rows and return 0 to the \"creator\" columnn. \n",
    "        return 0\n",
    "    pass\n",
    "            \n",
    "#df2=pd.read_csv('Data/Kickstarter.csv',converters={'creator':CustomParser2},header=0)\n",
    "#count and collect all the droped rows- so we can know the \"cost\" of te dropping (and maybe i will succed to solve it in the future)\n",
    "droped=df2.loc[df2['creator']==0,['creator']]\n",
    "df2=df2.loc[df2['creator']!=0]\n",
    "drop_list=list(droped.index)\n",
    "#df['creator'].iloc[drop_list]=df['creator'].iloc[drop_list].apply(lambda x: x.replace(' ',',')) is a start of a solution\n",
    "df=df.drop(index=drop_list)\n",
    "print('droped rows:',len(drop_list),drop_list)\n",
    "print (len(df))\n",
    "print (len(df2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 func that make diffent columns out of \"creator\" column (the auto func i used before don't works here. i did it manually)\n",
    "df2['creator_name']=df2['creator'].apply(lambda x: x['name'])\n",
    "df2['creator_id']=df2['creator'].apply(lambda x: x['id'])\n",
    "#\"inject\" it back to the original df\n",
    "df['creator_name']=df2['creator_name']\n",
    "df['creator_id']=df2['creator_id']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning func\n",
    "def clean(df):\n",
    "    data = df.copy()\n",
    "    #this is important beacuse this is the part we dicided  which columns entered the data set.\n",
    "    #the main structure is like in the exemple but i manipulate and add some additional columns i think we need to include(*marked) . \n",
    "    selected_cols = ['creator_name', #*\n",
    "                     'creator_id', #*\n",
    "                     'backers_count',\n",
    "                     'blurb',\n",
    "                     'is_starred', #*\n",
    "                     'category.id', #*\n",
    "                     'category.name',\n",
    "                     'category.parent_id',\n",
    "                     'category.slug',\n",
    "                     'country',\n",
    "                     'created_at',\n",
    "                     'currency',  \n",
    "                     'deadline',\n",
    "                     'goal',\n",
    "                     'launched_at',\n",
    "                     'spotlight',\n",
    "                     'staff_pick',\n",
    "                     'state',\n",
    "                     'usd_pledged',\n",
    "                     'usd_type']\n",
    "    data = data[selected_cols]\n",
    "    data['is_starred']=data['is_starred'].replace({1: True , None: False})\n",
    "    data = data.dropna()\n",
    "    successful = data['state'] == \"successful\"\n",
    "    failed = data['state'] == \"failed\"\n",
    "    cancelled = data['state'] == \"cancelled\"\n",
    "    suspended = data['state'] == \"suspended\"\n",
    "    data = data.loc[failed | successful | cancelled | suspended]\n",
    "    num_cols = ['usd_pledged',\n",
    "                'deadline',\n",
    "                'created_at',\n",
    "                'launched_at']\n",
    "    data[num_cols] = data[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    data['created_at'] = pd.to_datetime(data['created_at'],unit='s')\n",
    "    data['launched_at'] = pd.to_datetime(data['launched_at'],unit='s')\n",
    "    data['deadline'] = pd.to_datetime(data['deadline'],unit='s')\n",
    "    return data\n",
    "\n",
    "data = clean(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def engineer_features(data):\n",
    "    #make state 1 or 0\n",
    "    data['state'].replace('suspended','failed',inplace=True)   \n",
    "    data['state_num'] = data['state'].apply(lambda x: 1 if x=='successful' else 0)\n",
    "    #time to reletive time\n",
    "    data['launched_at_hr'] = data['launched_at'].apply(lambda x: x.hour) + 1\n",
    "    data['launched_at_day_in_week'] = data['launched_at'].apply(lambda x: x.dayofweek + 1)\n",
    "    data['launched_at_day_in_month'] = data['launched_at'].apply(lambda x: x.day ) #Elad's comment\n",
    "    data['launched_at_mo'] = data['launched_at'].apply(lambda x: x.month)\n",
    "    data['launched_at_yr'] = data['launched_at'].apply(lambda x: x.year)\n",
    "    data['deadline_hr'] = data['deadline'].apply(lambda x: x.hour) + 1\n",
    "    data['deadline_day_in_week'] = data['deadline'].apply(lambda x: x.dayofweek + 1) \n",
    "    data['deadline_day_in_month'] = data['deadline'].apply(lambda x: x.day ) #Elad's comment\n",
    "    data['deadline_mo'] = data['deadline'].apply(lambda x: x.month)\n",
    "    data['deadline_yr'] = data['deadline'].apply(lambda x: x.year)\n",
    "    data['created_at_hr'] = data['created_at'].apply(lambda x: x.hour) + 1\n",
    "    data['created_at_day_in_week'] = data['created_at'].apply(lambda x: x.dayofweek + 1) \n",
    "    data['created_at_day_in_month'] = data['created_at'].apply(lambda x: x.day )  #Elad's comment\n",
    "    data['created_at_mo'] = data['created_at'].apply(lambda x: x.month)\n",
    "    data['created_at_yr'] = data['created_at'].apply(lambda x: x.year)\n",
    "    data['count'] = 1\n",
    "    data['success'] = (data['state'] == 'successful')\n",
    "    data['launched-created'] = (data.launched_at - data.created_at).dt.components.days\n",
    "    data['deadline-launched'] = (data.deadline - data.launched_at).dt.components.days\n",
    "    data=data.drop(['launched_at','created_at','deadline'],axis=1) #drop original time col\n",
    "    data['pledge_perc']=data['usd_pledged']/data['goal']*100\n",
    "    return data\n",
    "data = engineer_features(data)\n",
    "data.info()\n",
    "data.to_csv('Data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import set\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "set(font_scale=2)\n",
    "b=sns.countplot(x='category.slug', hue='success',data=data)\n",
    "#b.axes.set_title(\"Title\",fontsize=30)\n",
    "b.set_xlabel(\"Categories\",fontsize=18)\n",
    "b.set_ylabel(\"Count\",fontsize=18)\n",
    "b.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP=np.clip(data['pledge_perc'], 0, 300)\n",
    "fig=PP.hist(bins = 200, figsize = (20,15),color='gold')\n",
    "fig.set_xlabel(\"% of Capital raised from initial goal\",fontsize=18,color='b')\n",
    "fig.set_ylabel(\"Count\",fontsize=18,color='b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.corr()\n",
    "corr_matrix[\"success\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix[(corr_matrix<1) & ((corr_matrix >= 0.2) | (corr_matrix <= -0.2)) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
